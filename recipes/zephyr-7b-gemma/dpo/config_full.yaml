# Model arguments
model_name_or_path: kykim0/gemma-2b-ultrachat-sft
torch_dtype: bfloat16

# Data training arguments
# For definitions, see: src/h4/training/config.py
dataset_mixer:
  allenai/ultrafeedback_binarized_cleaned: 1.0
dataset_splits:
- train_prefs
- test_prefs
preprocessing_num_workers: 12

# DPOTrainer arguments (2 GPU assumed)
bf16: true
beta: 0.05
do_eval: true
evaluation_strategy: steps
eval_steps: 100
gradient_accumulation_steps: 64
# gradient_accumulation_steps: 64
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: False
learning_rate: 5.0e-7
log_level: info
logging_steps: 10
lr_scheduler_type: cosine
max_length: 1024
max_prompt_length: 512
# num_train_epochs: 2
num_train_epochs: 3
optim: adamw_torch
run_name: capo-dpo
output_dir: /home/kykim/dev/checkpoints/alignment-handbook/g2b-uf-capo-dpo
bt_beta: null
soft_label_json: null
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
remove_unused_columns: false
push_to_hub: false
hub_model_id: null
report_to:
- wandb
save_strategy: epoch
save_total_limit: null
save_only_model: true
seed: 42
warmup_ratio: 0.1